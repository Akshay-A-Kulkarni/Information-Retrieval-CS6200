# Wikipedia Crawler

## 

Run with Python 3
- `python crawler.py`


- follow the prompted information,
Enter the seed URL and keywords


## 
Running results
- Task 1 BFS: maximum depth 3
- 
Task 1 DFS: maximum depth 6
- 
Task 2 BFS: maximum depth 3


## 
Download raw htmls
- `python downloadHTML.py`

- follow the prompted information, enter the text file containing wiki links

- output htmls in ./htmls
